{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6008 (pid 23112), started 23:18:06 ago. (Use '!kill 23112' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ca661730e8eb6b49\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ca661730e8eb6b49\");\n",
       "          const url = new URL(\"http://localhost\");\n",
       "          const port = 6008;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Running Tensorboard\n",
    "\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./mylogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2915 images belonging to 5 classes.\n",
      "Found 624 images belonging to 5 classes.\n",
      "Found 628 images belonging to 5 classes.\n",
      "Number Of Images In Training Dataset : 2915\n",
      "Number Of Images In Validation Dataset : 624\n",
      "Number Of Images In Validation Dataset : 628\n",
      "Total number of images: 4167\n"
     ]
    }
   ],
   "source": [
    "# Creating image generators\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "image_shape = (240, 240, 3) # I want the images to be square and not to big to speed up training.\n",
    "test_split_size = 0.15\n",
    "batch_size = 128\n",
    "rescale_factor = 1/255\n",
    "\n",
    "# Define the parameters for data augmentation\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=rescale_factor,\n",
    "    rotation_range=40,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "\n",
    "# Create the training dataset\n",
    "train_dataset = train_datagen.flow_from_directory(\n",
    "    'data/flowers_cleaned_split/train',\n",
    "    target_size=image_shape[:2],\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create the val dataset\n",
    "val_dataset = val_datagen.flow_from_directory(\n",
    "    'data/flowers_cleaned_split/val/',\n",
    "    target_size=image_shape[:2],\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create the test dataset\n",
    "test_dataset = test_datagen.flow_from_directory(\n",
    "    'data/flowers_cleaned_split/test/',\n",
    "    target_size=image_shape[:2],\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "\n",
    "print(f'Number Of Images In Training Dataset : {str(train_dataset.samples)}')\n",
    "print(f'Number Of Images In Validation Dataset : {str(val_dataset.samples)}')\n",
    "print(f'Number Of Images In Validation Dataset : {str(test_dataset.samples)}')\n",
    "print(f'Total number of images: {train_dataset.samples+val_dataset.samples+test_dataset.samples}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Creating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Steps Per Epoch : Training -> 22\n",
      "Steps : Validation -> 4\n"
     ]
    }
   ],
   "source": [
    "# Defining number of steps for training & validation of model\n",
    "steps_per_epoch = train_dataset.samples // batch_size\n",
    "validation_steps = val_dataset.samples // batch_size\n",
    "\n",
    "print('Steps Per Epoch : Training -> ' + str(steps_per_epoch))\n",
    "print('Steps : Validation -> ' + str(validation_steps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, Activation, BatchNormalization\n",
    "from keras import regularizers\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "from pathlib import Path\n",
    "from time import strftime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WindowsPath('my_logs/run_2023_12_13_22_49_57_added_1_more_conv')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Callbacks\n",
    "\n",
    "# Defining tensorboard callback for logging and visualization\n",
    "def get_run_logdir(custom_text=\"\", root_logdir=\"my_logs\"):\n",
    "    formatted_time = strftime(\"run_%Y_%m_%d_%H_%M_%S\")\n",
    "    if custom_text:\n",
    "        custom_text = \"_\" + custom_text\n",
    "    return Path(root_logdir) / (formatted_time + custom_text)\n",
    "\n",
    "\n",
    "run_logdir = get_run_logdir(\"added_1_more_conv\")\n",
    "\n",
    "tensorboard_cb = TensorBoard(run_logdir, profile_batch=(100, 200))\n",
    "\n",
    "# Defining earlystopping callback to stop training if model isnt getting better\n",
    "early_stop_cb = EarlyStopping(monitor=\"val_loss\", patience=10)\n",
    "run_logdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\hakan\\.virtualenvs\\Deep-learning-lab-O8p5G3Ji\\lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\hakan\\.virtualenvs\\Deep-learning-lab-O8p5G3Ji\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "\n",
    "# add layers to model\n",
    "model.add(\n",
    "    Conv2D(\n",
    "        filters=32,\n",
    "        padding=\"same\",\n",
    "        kernel_size=(3, 3),\n",
    "        input_shape=image_shape,\n",
    "        activation=\"relu\",\n",
    "    )\n",
    ")\n",
    "\n",
    "model.add(\n",
    "    Conv2D(\n",
    "        filters=32,\n",
    "        padding=\"same\",\n",
    "        kernel_size=(3, 3),\n",
    "    )\n",
    ")\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(\n",
    "    Conv2D(\n",
    "        filters=64,\n",
    "        padding=\"same\",\n",
    "        kernel_size=(3, 3),\n",
    "    )\n",
    ")\n",
    "\n",
    "model.add(Conv2D(filters=64, padding=\"same\", kernel_size=(3, 3), activation=\"relu\"))\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(\n",
    "    Conv2D(\n",
    "        filters=128,\n",
    "        padding=\"same\",\n",
    "        kernel_size=(3, 3),\n",
    "    )\n",
    ")\n",
    "\n",
    "model.add(Conv2D(filters=128, padding=\"same\", kernel_size=(3, 3), activation=\"relu\"))\n",
    "model.add(Conv2D(filters=128, padding=\"same\", kernel_size=(3, 3), activation=\"relu\"))\n",
    "\n",
    "model.add(MaxPool2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation=\"relu\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(5, activation=\"softmax\"))\n",
    "\n",
    "# Setting compilation parameters\n",
    "learning_rate = 0.001\n",
    "optimizer = Adam(learning_rate=learning_rate)\n",
    "model.compile(\n",
    "    loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 240, 240, 32)      896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 240, 240, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 120, 120, 32)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 120, 120, 32)      0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 120, 120, 64)      18496     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 120, 120, 64)      36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 60, 60, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 60, 60, 64)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 60, 60, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 60, 60, 128)       147584    \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 60, 60, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 30, 30, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 30, 30, 128)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 115200)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               58982912  \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 5)                 2565      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 59420069 (226.67 MB)\n",
      "Trainable params: 59420069 (226.67 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Checking model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Launching Tensorboard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir=./mylogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop_cb = EarlyStopping(monitor=\"val_loss\", patience=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "22/22 [==============================] - 262s 11s/step - loss: 0.6607 - accuracy: 0.7463 - val_loss: 0.6692 - val_accuracy: 0.7617\n",
      "Epoch 2/10\n",
      "22/22 [==============================] - 236s 10s/step - loss: 0.6489 - accuracy: 0.7503 - val_loss: 0.6467 - val_accuracy: 0.7812\n",
      "Epoch 3/10\n",
      "22/22 [==============================] - 268s 12s/step - loss: 0.6536 - accuracy: 0.7499 - val_loss: 0.6632 - val_accuracy: 0.7754\n",
      "Epoch 4/10\n",
      "22/22 [==============================] - 220s 10s/step - loss: 0.6548 - accuracy: 0.7510 - val_loss: 0.6750 - val_accuracy: 0.7715\n",
      "Epoch 5/10\n",
      "22/22 [==============================] - 223s 10s/step - loss: 0.6436 - accuracy: 0.7610 - val_loss: 0.6518 - val_accuracy: 0.7520\n",
      "Epoch 6/10\n",
      "22/22 [==============================] - 231s 10s/step - loss: 0.6489 - accuracy: 0.7607 - val_loss: 0.6526 - val_accuracy: 0.7715\n",
      "Epoch 7/10\n",
      "22/22 [==============================] - 304s 14s/step - loss: 0.6276 - accuracy: 0.7614 - val_loss: 0.6679 - val_accuracy: 0.7676\n",
      "Epoch 8/10\n",
      "22/22 [==============================] - 248s 11s/step - loss: 0.6144 - accuracy: 0.7607 - val_loss: 0.6521 - val_accuracy: 0.7461\n",
      "Epoch 9/10\n",
      "22/22 [==============================] - 262s 12s/step - loss: 0.6856 - accuracy: 0.7481 - val_loss: 0.6074 - val_accuracy: 0.7793\n",
      "Epoch 10/10\n",
      "22/22 [==============================] - 252s 11s/step - loss: 0.6533 - accuracy: 0.7481 - val_loss: 0.6278 - val_accuracy: 0.7832\n"
     ]
    }
   ],
   "source": [
    "# Training model\n",
    "history = model.fit(train_dataset,epochs=10,steps_per_epoch = steps_per_epoch,\n",
    "                    validation_data = val_dataset, validation_steps=validation_steps,\n",
    "                    verbose=True, callbacks=[early_stop_cb, tensorboard_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 12s 2s/step - loss: 0.6303 - accuracy: 0.7596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6303080320358276, 0.7595541477203369]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Svar på frågor:\n",
    "- Motivera din modellarkitektur och val av relevanta hyperparametrar.  \n",
    "    Genom experiment med olika data augmentation, regularisering, lagerstorlek och annat så märkte jag att det som gjorde störst positiv skillnad vadrantal conv-lager. \n",
    "- Vilka aktiveringsfunktioner har du använt? Varför?   \n",
    "    ReLu - pga standard, ej experimenterat mycket med detta.\n",
    "- Vilken loss funktion har du använt? Varför?  \n",
    "    Adam - pga standard, ej experimenterat mycket här.\n",
    "- Har du använt någon databehandling? Varför?   \n",
    "    Ja, jag har provat ganska mycket augmentation eftersom datasetet är relativt litet. Rotation, spegelvändning, shear och zoomning känns allihopa som att det inte förstör bilden. Möjligen blir bilder där människor ingår lite konstiga vid rotation, men det borde vara försumbart.\n",
    "- Har du använt någon regulariseringsteknik? Motivera.   \n",
    "    Jag har provat L1 och L2, batch normalization samt Dropout. Det som fungerade bäst var Dropout och det var det enda jag behöll till sist.\n",
    "- Hur har modellen utvärderats?  \n",
    "    Jag har använt Tensorboard och kört modellerna cirka 10 epoker åt gången, jag körde för det mesta early stopping på \"val_loss\" med patience 5 för att inte fastna för länge på en dålig modell.\n",
    "- Är prestandan bra? Varför/ varför inte?   \n",
    "    Jag kom till slut upp till cirka 0.75 accuracy på testdatan vilket jag är nöjd med.\n",
    "- Vad hade du kunnat göra för att förbättra den ytterligare?  \n",
    "    Antagligen göra ännu fler convlager eller denselager i slutet. Då skulle det dock börja ta lite för lång tid att träna."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deep-learning-lab-O8p5G3Ji",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
